{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuT9uDhp-_Ym",
        "outputId": "eb99e42d-8c80-4540-eb78-490e6a8718c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99IVdLYbHIPw"
      },
      "source": [
        "Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6hGNWCX-c4H",
        "outputId": "bd3d1d87-b0a7-4a49-ace5-3763c0dc5626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory '/content/drive/MyDrive/New_dataset' created.\n",
            "Files unzipped and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Path to the zip file you want to unzip\n",
        "zip_file_path = '/content/drive/MyDrive/deepfake_new.zip'\n",
        "\n",
        "# Path to the directory where you want to save the unzipped files\n",
        "output_dir = '/content/drive/MyDrive/New_dataset'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "    print(f\"Directory '{output_dir}' created.\")\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "print(\"Files unzipped and saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuVnZ6lH_m_z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "def get_xception_based_model():\n",
        "    base_model = Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(128, 128, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(units=1024, activation='relu')(x)\n",
        "    outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd4m82Q2iL9u"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [128, 128])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def predict_with_threshold(model, image_path, threshold=0.5):\n",
        "    img = load_and_preprocess_image(image_path)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)[0][0]\n",
        "\n",
        "    print(f\"Raw Prediction Score: {prediction:.4f}.\")\n",
        "\n",
        "    if prediction >= threshold:\n",
        "        pred_class = 'real'\n",
        "    else:\n",
        "        pred_class = 'fake'\n",
        "\n",
        "    print(f\"Predicted Class ({pred_class}), Probability - {prediction:.4f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRl5ogic_T7D",
        "outputId": "427de5bc-0173-4918-9055-5d2232038d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1437 images belonging to 2 classes.\n",
            "Found 604 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 390s 60s/step - loss: 0.7060 - accuracy: 0.5170 - val_loss: 0.6865 - val_accuracy: 0.5430\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.6697 - accuracy: 0.5825 - val_loss: 0.6672 - val_accuracy: 0.6142\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.6505 - accuracy: 0.6180 - val_loss: 0.6516 - val_accuracy: 0.5977\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.6209 - accuracy: 0.6590 - val_loss: 0.6541 - val_accuracy: 0.6076\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.5793 - accuracy: 0.7035 - val_loss: 0.6387 - val_accuracy: 0.6474\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 33s 6s/step - loss: 0.5733 - accuracy: 0.7022 - val_loss: 0.6204 - val_accuracy: 0.6689\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 33s 5s/step - loss: 0.5528 - accuracy: 0.7126 - val_loss: 0.6202 - val_accuracy: 0.6738\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.5139 - accuracy: 0.7425 - val_loss: 0.7047 - val_accuracy: 0.6291\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.5123 - accuracy: 0.7404 - val_loss: 0.6509 - val_accuracy: 0.6275\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.4906 - accuracy: 0.7662 - val_loss: 0.6841 - val_accuracy: 0.6523\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 32s 5s/step - loss: 0.4509 - accuracy: 0.7815 - val_loss: 0.6674 - val_accuracy: 0.6540\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 32s 5s/step - loss: 0.4396 - accuracy: 0.7926 - val_loss: 0.7748 - val_accuracy: 0.6142\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.4165 - accuracy: 0.8142 - val_loss: 0.7542 - val_accuracy: 0.6093\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 35s 6s/step - loss: 0.3883 - accuracy: 0.8225 - val_loss: 0.7631 - val_accuracy: 0.6308\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 31s 6s/step - loss: 0.3343 - accuracy: 0.8546 - val_loss: 0.8867 - val_accuracy: 0.6391\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 33s 6s/step - loss: 0.3506 - accuracy: 0.8455 - val_loss: 0.8561 - val_accuracy: 0.6407\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 32s 5s/step - loss: 0.3105 - accuracy: 0.8699 - val_loss: 0.9099 - val_accuracy: 0.6010\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 37s 7s/step - loss: 0.2890 - accuracy: 0.8713 - val_loss: 0.9257 - val_accuracy: 0.6192\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 32s 6s/step - loss: 0.2727 - accuracy: 0.8859 - val_loss: 0.9274 - val_accuracy: 0.6142\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 32s 5s/step - loss: 0.2238 - accuracy: 0.9074 - val_loss: 1.1361 - val_accuracy: 0.5993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__==\"__main__\":\n",
        "    xception_model = get_xception_based_model()\n",
        "\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      rotation_range=10.,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1)\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "      directory='/content/drive/MyDrive/dataset/training',\n",
        "      target_size=(128, 128),\n",
        "      batch_size=256,\n",
        "      class_mode='binary')\n",
        "\n",
        "    validate_generator = validation_datagen.flow_from_directory(\n",
        "      directory='/content/drive/MyDrive/dataset/test',\n",
        "      target_size=(128, 128),\n",
        "      batch_size=256,\n",
        "      class_mode='binary')\n",
        "\n",
        "    epochs = 20\n",
        "\n",
        "    history = xception_model.fit(train_generator, epochs=epochs, validation_data=validate_generator)\n",
        "\n",
        "    xception_model.save('best_xception_model.h5')\n",
        "\n",
        "    # # Testing\n",
        "    # image_path = '<YOUR_IMAGE_PATH>'\n",
        "    # predict_with_threshold(xception_model, image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8i75X9Fih5h"
      },
      "outputs": [],
      "source": [
        "# prompt: give me a code to load my ml model\n",
        "\n",
        "xception_model = tf.keras.models.load_model('/content/drive/MyDrive/model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0rKHDJ9BB7c",
        "outputId": "afcd9541-26b7-4410-d777-d360e7b1e77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "Raw Prediction Score: 0.3366.\n",
            "Predicted Class (fake), Probability - 0.3366.\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Raw Prediction Score: 0.0813.\n",
            "Predicted Class (fake), Probability - 0.0813.\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Raw Prediction Score: 0.9925.\n",
            "Predicted Class (real), Probability - 0.9925.\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Raw Prediction Score: 0.8693.\n",
            "Predicted Class (real), Probability - 0.8693.\n"
          ]
        }
      ],
      "source": [
        " # Testing\n",
        "\n",
        "image_path = '/content/drive/MyDrive/Dataset_new/dataset/test/real/real_00780.jpg'\n",
        "predict_with_threshold(xception_model, image_path)\n",
        "\n",
        "image_path = '/content/drive/MyDrive/Dataset_new/dataset/test/real/real_00787.jpg'\n",
        "predict_with_threshold(xception_model, image_path)\n",
        "\n",
        "image_path = '/content/drive/MyDrive/Dataset_new/dataset/test/fake/mid_179_1111.jpg'\n",
        "predict_with_threshold(xception_model, image_path)\n",
        "\n",
        "image_path = '/content/drive/MyDrive/Dataset_new/dataset/test/fake/mid_182_1111.jpg'\n",
        "predict_with_threshold(xception_model, image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26-JdwL9_PCG",
        "outputId": "8d7c1d3d-7ef6-43af-ea72-cf80b548a39f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 604 images belonging to 2 classes.\n",
            "19/19 [==============================] - 8s 393ms/step - loss: 0.5707 - accuracy: 0.7086\n",
            "Test Loss: 0.5707\n",
            "Test Accuracy: 0.7086\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_generator = validation_datagen.flow_from_directory(\n",
        "    directory='/content/drive/MyDrive/New_dataset/dataset/test',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False)\n",
        "\n",
        "test_loss, test_accuracy = xception_model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "xception_model.save('/content/drive/MyDrive/final_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SqNOm-EfYmvY"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "xception_model.save('/content/drive/MyDrive/final_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MgbTnZSdOKg"
      },
      "source": [
        "**RESNET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdpV2ORqPUBm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "def create_base_model():\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "    return base_model\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [128, 128])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def predict_with_threshold(model, image_path, threshold=0.5):\n",
        "    img = load_and_preprocess_image(image_path)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img).flatten()[0]  # Extract the first element\n",
        "\n",
        "    print(f\"Raw Prediction Score: {prediction:.4f}.\")\n",
        "\n",
        "    if prediction >= threshold:\n",
        "        pred_class = 'real'\n",
        "    else:\n",
        "        pred_class = 'fake'\n",
        "\n",
        "    print(f\"Predicted Class ({pred_class}), Probability - {prediction:.4f}.\")\n",
        "\n",
        "def get_resnet_based_model():\n",
        "    base_model = create_base_model()\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(128, 128, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(units=1024, activation='relu')(x)\n",
        "    outputs = tf.keras.layers.Dense(units=1, activation='linear')(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    opt = Adam(learning_rate=0.0001)\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5aWjTX8S6dJ",
        "outputId": "bf5df641-4f2d-4460-dd4c-a82774617268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1437 images belonging to 2 classes.\n",
            "Found 604 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 80s 6s/step - loss: 1.2279 - mean_absolute_percentage_error: 378171968.0000 - val_loss: 0.3279 - val_mean_absolute_percentage_error: 111692576.0000\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.3928 - mean_absolute_percentage_error: 231090272.0000 - val_loss: 0.2508 - val_mean_absolute_percentage_error: 241139584.0000\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 31s 6s/step - loss: 0.2553 - mean_absolute_percentage_error: 261860176.0000 - val_loss: 0.2595 - val_mean_absolute_percentage_error: 202076656.0000\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 36s 6s/step - loss: 0.2584 - mean_absolute_percentage_error: 233523824.0000 - val_loss: 0.2640 - val_mean_absolute_percentage_error: 308699072.0000\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2583 - mean_absolute_percentage_error: 247944256.0000 - val_loss: 0.2946 - val_mean_absolute_percentage_error: 355288736.0000\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2562 - mean_absolute_percentage_error: 252233440.0000 - val_loss: 0.2550 - val_mean_absolute_percentage_error: 284810208.0000\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2497 - mean_absolute_percentage_error: 246028848.0000 - val_loss: 0.2560 - val_mean_absolute_percentage_error: 288164064.0000\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2516 - mean_absolute_percentage_error: 253641520.0000 - val_loss: 0.2533 - val_mean_absolute_percentage_error: 278538144.0000\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 32s 6s/step - loss: 0.2521 - mean_absolute_percentage_error: 253690720.0000 - val_loss: 0.2512 - val_mean_absolute_percentage_error: 266938160.0000\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 31s 6s/step - loss: 0.2596 - mean_absolute_percentage_error: 241612896.0000 - val_loss: 0.2623 - val_mean_absolute_percentage_error: 305271040.0000\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2551 - mean_absolute_percentage_error: 251190144.0000 - val_loss: 0.2559 - val_mean_absolute_percentage_error: 288037280.0000\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2505 - mean_absolute_percentage_error: 234619520.0000 - val_loss: 0.2564 - val_mean_absolute_percentage_error: 289941408.0000\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2492 - mean_absolute_percentage_error: 260087344.0000 - val_loss: 0.2502 - val_mean_absolute_percentage_error: 243149952.0000\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 32s 5s/step - loss: 0.2522 - mean_absolute_percentage_error: 242587120.0000 - val_loss: 0.2618 - val_mean_absolute_percentage_error: 304283104.0000\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2491 - mean_absolute_percentage_error: 242970496.0000 - val_loss: 0.2505 - val_mean_absolute_percentage_error: 261639760.0000\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2504 - mean_absolute_percentage_error: 263174560.0000 - val_loss: 0.2506 - val_mean_absolute_percentage_error: 237123728.0000\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2554 - mean_absolute_percentage_error: 234359296.0000 - val_loss: 0.2589 - val_mean_absolute_percentage_error: 297500480.0000\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 31s 6s/step - loss: 0.2507 - mean_absolute_percentage_error: 235132384.0000 - val_loss: 0.2523 - val_mean_absolute_percentage_error: 274521504.0000\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2509 - mean_absolute_percentage_error: 259572656.0000 - val_loss: 0.2501 - val_mean_absolute_percentage_error: 258456784.0000\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2501 - mean_absolute_percentage_error: 250264560.0000 - val_loss: 0.2524 - val_mean_absolute_percentage_error: 275271328.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "if __name__==\"__main__\":\n",
        "    resnet_model = get_resnet_based_model()\n",
        "\n",
        "    # Optionally uncomment the next line to visualize the architecture summary\n",
        "    # resnet_model.summary()\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      rotation_range=10.,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1)\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "      directory='/content/drive/MyDrive/dataset/training',\n",
        "      target_size=(128, 128),\n",
        "      batch_size=256,\n",
        "      class_mode='binary')\n",
        "\n",
        "    validate_generator = validation_datagen.flow_from_directory(\n",
        "      directory='/content/drive/MyDrive/dataset/test',\n",
        "      target_size=(128, 128),\n",
        "      batch_size=256,\n",
        "      class_mode='binary')\n",
        "\n",
        "    epochs = 20\n",
        "\n",
        "    history = resnet_model.fit(train_generator, epochs=epochs, validation_data=validate_generator)\n",
        "\n",
        "    resnet_model.save('best_resnet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuLgn5hja9MD",
        "outputId": "b8e33d91-2171-4ac5-d80f-c16996d2d5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 546ms/step\n",
            "Raw Prediction Score: 0.5499.\n",
            "Predicted Class (real), Probability - 0.5499.\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Raw Prediction Score: 0.5527.\n",
            "Predicted Class (real), Probability - 0.5527.\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Raw Prediction Score: 0.5479.\n",
            "Predicted Class (real), Probability - 0.5479.\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Raw Prediction Score: 0.5497.\n",
            "Predicted Class (real), Probability - 0.5497.\n"
          ]
        }
      ],
      "source": [
        "    # Testing\n",
        "    image_path = '/content/drive/MyDrive/dataset/face_pred/check.jpg'\n",
        "    predict_with_threshold(resnet_model, image_path)\n",
        "\n",
        "        # Testing\n",
        "    image_path = '/content/drive/MyDrive/dataset/face_pred/check2.jpg'\n",
        "    predict_with_threshold(resnet_model, image_path)\n",
        "\n",
        "        # Testing\n",
        "    image_path = '/content/drive/MyDrive/dataset/face_pred/check3.jpg'\n",
        "    predict_with_threshold(resnet_model, image_path)\n",
        "\n",
        "        # Testing\n",
        "    image_path = '/content/drive/MyDrive/dataset/face_pred/check4.jpg'\n",
        "    predict_with_threshold(resnet_model, image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW9IXQwqcAnR"
      },
      "source": [
        "**EFFICIENT NET**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQApC0vjhvAq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "def create_base_model():\n",
        "    base_model = EfficientNetB0(include_top=False, input_shape=(128, 128, 3), weights='imagenet')\n",
        "    return base_model\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [128, 128])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def predict_with_threshold(model, image_path, ground_truth=None, threshold=0.5):\n",
        "    img = load_and_preprocess_image(image_path)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    probabilities = model.predict(img)\n",
        "\n",
        "    print(f\"Probability: {probabilities.flatten()[0]:.4f}\")\n",
        "\n",
        "    if ground_truth is not None:\n",
        "        accuracy = (probabilities.flatten()[0] > threshold) == bool(ground_truth)\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    if probabilities.flatten()[0] >= threshold:\n",
        "        pred_class = 'real'\n",
        "    else:\n",
        "        pred_class = 'fake'\n",
        "\n",
        "    print(f\"Predicted Class ({pred_class})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wConv2geh1LM",
        "outputId": "23ba1e4f-1ac7-43e6-e7c5-d804eebe0f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1437 images belonging to 2 classes.\n",
            "Found 604 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 65s 5s/step - loss: 0.4752 - mean_absolute_percentage_error: 270686976.0000 - val_loss: 0.2710 - val_mean_absolute_percentage_error: 177537648.0000\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2633 - mean_absolute_percentage_error: 248255296.0000 - val_loss: 0.2505 - val_mean_absolute_percentage_error: 240047520.0000\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2509 - mean_absolute_percentage_error: 234101440.0000 - val_loss: 0.2636 - val_mean_absolute_percentage_error: 308203616.0000\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 34s 6s/step - loss: 0.2503 - mean_absolute_percentage_error: 249619872.0000 - val_loss: 0.2508 - val_mean_absolute_percentage_error: 263762144.0000\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2497 - mean_absolute_percentage_error: 250752736.0000 - val_loss: 0.2523 - val_mean_absolute_percentage_error: 273686272.0000\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 30s 6s/step - loss: 0.2490 - mean_absolute_percentage_error: 254027792.0000 - val_loss: 0.2503 - val_mean_absolute_percentage_error: 257991984.0000\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 32s 6s/step - loss: 0.2502 - mean_absolute_percentage_error: 243960128.0000 - val_loss: 0.2569 - val_mean_absolute_percentage_error: 291467872.0000\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2507 - mean_absolute_percentage_error: 239659824.0000 - val_loss: 0.2523 - val_mean_absolute_percentage_error: 274254528.0000\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2491 - mean_absolute_percentage_error: 259835120.0000 - val_loss: 0.2500 - val_mean_absolute_percentage_error: 254322704.0000\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 34s 6s/step - loss: 0.2491 - mean_absolute_percentage_error: 238739712.0000 - val_loss: 0.2530 - val_mean_absolute_percentage_error: 277337312.0000\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 34s 6s/step - loss: 0.2503 - mean_absolute_percentage_error: 249912032.0000 - val_loss: 0.2500 - val_mean_absolute_percentage_error: 247622704.0000\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2479 - mean_absolute_percentage_error: 244564960.0000 - val_loss: 0.2574 - val_mean_absolute_percentage_error: 293202464.0000\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2516 - mean_absolute_percentage_error: 247391424.0000 - val_loss: 0.2500 - val_mean_absolute_percentage_error: 249128752.0000\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2524 - mean_absolute_percentage_error: 266910592.0000 - val_loss: 0.2500 - val_mean_absolute_percentage_error: 247546880.0000\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2506 - mean_absolute_percentage_error: 228547536.0000 - val_loss: 0.2578 - val_mean_absolute_percentage_error: 294074592.0000\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2488 - mean_absolute_percentage_error: 256252096.0000 - val_loss: 0.2502 - val_mean_absolute_percentage_error: 241950368.0000\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 30s 6s/step - loss: 0.2526 - mean_absolute_percentage_error: 250949696.0000 - val_loss: 0.2587 - val_mean_absolute_percentage_error: 296571296.0000\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 30s 6s/step - loss: 0.2486 - mean_absolute_percentage_error: 240917904.0000 - val_loss: 0.2500 - val_mean_absolute_percentage_error: 249721232.0000\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 31s 5s/step - loss: 0.2491 - mean_absolute_percentage_error: 255175776.0000 - val_loss: 0.2522 - val_mean_absolute_percentage_error: 273592768.0000\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 30s 5s/step - loss: 0.2484 - mean_absolute_percentage_error: 245413008.0000 - val_loss: 0.2518 - val_mean_absolute_percentage_error: 270995264.0000\n"
          ]
        }
      ],
      "source": [
        "if __name__==\"__main__\":\n",
        "    efficientnet_model = get_efficientnet_based_model()\n",
        "\n",
        "    # Optionally uncomment the next line to visualize the architecture summary\n",
        "    # efficientnet_model.summary()\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      rotation_range=10.,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1)\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "      directory='/content/drive/MyDrive/dataset/training',\n",
        "      target_size=(128, 128),\n",
        "      batch_size=256,\n",
        "      class_mode='binary')\n",
        "\n",
        "    validate_generator = validation_datagen.flow_from_directory(\n",
        "      directory='/content/drive/MyDrive/dataset/test',\n",
        "      target_size=(128, 128),\n",
        "      batch_size=256,\n",
        "      class_mode='binary')\n",
        "\n",
        "    epochs = 20\n",
        "\n",
        "    history = efficientnet_model.fit(train_generator, epochs=epochs, validation_data=validate_generator)\n",
        "\n",
        "    efficientnet_model.save('best_efficientnet_model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zybh4XNiL3z",
        "outputId": "e4bad863-b968-49ad-9fef-5e0fc053d054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n",
            "Probability: 0.5430\n",
            "Predicted Class (real)\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Probability: 0.5422\n",
            "Predicted Class (real)\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Probability: 0.5420\n",
            "Predicted Class (real)\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Probability: 0.5418\n",
            "Predicted Class (real)\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "image_path = '/content/drive/MyDrive/dataset/face_pred/check.jpg'\n",
        "predict_with_threshold(efficientnet_model, image_path)\n",
        "\n",
        "image_path = '/content/drive/MyDrive/dataset/face_pred/check2.jpg'\n",
        "predict_with_threshold(efficientnet_model, image_path)\n",
        "\n",
        "image_path = '/content/drive/MyDrive/dataset/face_pred/check3.jpg'\n",
        "predict_with_threshold(efficientnet_model, image_path)\n",
        "\n",
        "image_path = '/content/drive/MyDrive/dataset/face_pred/check4.jpg'\n",
        "predict_with_threshold(efficientnet_model, image_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
